{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb0611d-9ede-4fd9-94f4-4b908d860d1a",
   "metadata": {},
   "source": [
    "# Exploring a Single Subject\n",
    "\n",
    "The purpose of this notebook is to explore a single subject from the Pathstone YAC dataset.\n",
    "\n",
    "Code snippets and functions are intended to be left alone and run as a standalone application.\n",
    "\n",
    "Below are the common configurations that a student could reasonably expect to change during exploration. Each will contain a brief explanation as to their intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f62884-7382-4589-94e4-913a0f40b45c",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- cluster of electrodes - prof problem - send email\n",
    "\n",
    "- area averages - prof problem; need timings; see below\n",
    "\n",
    "- problems of rejecting bad epochs and equalizing trial counts\n",
    "\n",
    "- expand conditions/channels for peak picking - me; trivial\n",
    "\n",
    "- write final peaks to file, etc - me\n",
    "\n",
    "- export waveforms to df\n",
    "\n",
    "- average 3 points around - extend it to be optional\n",
    "\n",
    "p3 - > (3,4)ms, (4,5), (5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7463de8-74e8-4475-800b-b504174c4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject to run the picking procedure on\n",
    "subject_id = '1014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141ff47f-646d-4c50-a735-3b9187f71457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EEG Configuration\n",
    "filter_freqs = (1.0, 30.0) # Filter data from (low_freq, high_freq)\n",
    "channel_interest = ['E75', 'E6', 'E62'] # Channels to pick for peaks\n",
    "condition_interest = ['VO21', 'combine'] # Conditions to pick for peaks\n",
    "epoch_tmin = -0.1 # Baseline to stimulus onset in seconds, negative implies before stimulus\n",
    "epoch_tmax = 1.0 # Duration after stimulus of epoch\n",
    "reject_criteria = {'eeg': 200e-6} # Reject trials that have X-microvolt peak to peak differences\n",
    "p1_def   = (0.060, 0.150) # P1 peak interval definition in seconds\n",
    "n170_def = (0.130, 0.220) # N170 peak interval definition in seconds\n",
    "p3_def   = (0.250, 0.850) # P3 peak interval definition in seconds\n",
    "\n",
    "# Plotting Configuration\n",
    "plot_raw        = False # If true, open raw recording scrollplot\n",
    "plot_components = False # If true, open component scrollplot\n",
    "plot_cleaned    = False # If true, open cleaned recording scrollplot\n",
    "\n",
    "save_epoched = False # If true, saves the epoched and cleaned version of the subject to file for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd8f0cc-089c-4195-a2a2-59404dec4a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n",
      "Extracting EDF parameters from /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Documents/eeg-dev/mne-qt-browser/mne_qt_browser/_pg_figure.py:55: FutureWarning: mne.io.pick.channel_indices_by_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "  from mne.io.pick import (_DATA_CH_TYPES_ORDER_DEFAULT,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading events from /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_events.tsv.\n",
      "Reading channel info from /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_channels.tsv.\n",
      "Reading electrode coords from /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_space-CapTrak_electrodes.tsv.\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_ica1_ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Reading /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_ica2_ica.fif ...\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Documents/pylossless/pylossless/pipeline.py:1199: RuntimeWarning: participants.tsv file not found for /home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_eeg.edf\n",
      "  self.raw = mne_bids.read_raw_bids(derivatives_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>LosslessPipeline</h3><table><tr><td><strong>Raw</strong></td><td>('/home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_eeg.edf',)</td></tr><tr><td><strong>Config</strong></td><td>/home/tyler/Documents/eeg-dev/projects/pathstone/derivatives/pylossless/sub-YAC1014/eeg/sub-YAC1014_task-afd_ll_config.yaml</td></tr></table><details><summary><strong>Flagged Channels</strong></summary><table><tr><td>Noisy</td><td>['E25']</td></tr><tr><td>Bridged</td><td>['E106']</td></tr><tr><td>Uncorrelated</td><td>None</td></tr><tr><td>Rank</td><td>['E17']</td></tr></table></details><details><summary><strong>Flagged ICs</strong></summary><table><tr><td>EOG (Eye)</td><td>['ICA001', 'ICA004', 'ICA017', 'ICA059']</td></tr><tr><td>ECG (Heart)</td><td>[]</td></tr><tr><td>Muscle</td><td>['ICA022', 'ICA023', 'ICA043', 'ICA050', 'ICA054']</td></tr><tr><td>Line Noise</td><td>[]</td></tr><tr><td>Channel Noise</td><td>[]</td></tr></table></details><details><summary><strong>Flagged Times (Total)</strong></summary><table><tr><td>BAD_LL_noisy</td><td>[] seconds</td></tr><tr><td>BAD_LL_uncorrelated</td><td>[] seconds</td></tr><tr><td>BAD_LL_noisy_ICs</td><td>[] seconds</td></tr></table></details>"
      ],
      "text/plain": [
       "<pylossless.pipeline.LosslessPipeline at 0x7f8619584790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import pylossless as ll\n",
    "import matplotlib.pyplot as plt\n",
    "mne.viz.set_browser_backend('qt')\n",
    "\n",
    "project_path = '~/Documents/eeg-dev/projects/pathstone/'\n",
    "raw_path = f'{project_path}/sub-YAC{subject_id}/eeg/sub-YAC{subject_id}_task-AttnCtrl_eeg.edf'\n",
    "derivative_path = f'{project_path}/derivatives/pylossless/sub-YAC{subject_id}/eeg/sub-YAC{subject_id}_task-afd_eeg.edf'\n",
    "\n",
    "ll_state = ll.LosslessPipeline()\n",
    "ll_state = ll_state.load_ll_derivative(derivative_path)\n",
    "ll_state.raw.info['bads'] = ll_state.flags['ch'].get_flagged()\n",
    "ll_state.ica2.exclude = [index for index,comp in ll_state.flags['ic'].iterrows() if comp['ic_type'] in ['eog', 'ecg', 'muscle', 'line_noise', 'channel_noise']]\n",
    "ll_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a6774-8345-43ce-87d2-a5867e271420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "if plot_raw:\n",
    "    ll_state.raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e5475-803d-4099-b6dc-ea67f8eeec20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "if plot_components:\n",
    "    fig = ll_state.ica2.plot_sources(ll_state.raw, theme='light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868dd4e-6220-429a-b47f-c5a0db8bac10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_state = ll_state.raw.copy()\n",
    "cleaned_state.load_data()\n",
    "ll_state.ica2.apply(cleaned_state)\n",
    "cleaned_state = cleaned_state.interpolate_bads()\n",
    "cleaned_state = cleaned_state.filter(l_freq=filter_freqs[0], h_freq=filter_freqs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393439c0-2230-450b-b8f8-0a4f046e5292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "if plot_cleaned:\n",
    "    cleaned_state.plot(theme='light')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb8b73-bcff-4679-84d4-e46f3a5c8e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = mne.io.read_raw_edf(f'sub-YAC{subject_id}/eeg/sub-YAC{subject_id}_task-AttnCtrl_eeg.edf')\n",
    "base_events, event_dict = mne.events_from_annotations(raw_data)\n",
    "\n",
    "# Programmatically relabel events\n",
    "event_dict['VO24/combine'] = event_dict.pop('VO24')\n",
    "event_dict['VO25/combine'] = event_dict.pop('VO25')\n",
    "\n",
    "event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9bb1b7-ceb1-4759-b70b-aff93878378a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    cleaned_state,\n",
    "    base_events,\n",
    "    picks=channel_interest,\n",
    "    event_id=event_dict,\n",
    "    tmin=epoch_tmin,\n",
    "    tmax=epoch_tmax,\n",
    "    reject=reject_criteria,\n",
    "    preload=True,\n",
    "    event_repeated='merge',\n",
    ")\n",
    "if save_epoched:\n",
    "    epochs.save(f'yac_{subject_id}_pylqcr_eeg.fif', overwrite=True)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf8eb2-36dc-430f-b116-6d642018f3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "evokeds = {}\n",
    "for chan in channel_interest:\n",
    "    for cond in condition_interest:\n",
    "        evokeds[cond] = epochs[cond].average()\n",
    "\n",
    "    fig = mne.viz.plot_compare_evokeds(evokeds, picks=chan, combine='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd43260-9c4d-428b-96db-989a89337831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below functions are helper functions for peak picking\n",
    "\n",
    "def max_index_and_value(series, find_max=True):\n",
    "    if find_max:\n",
    "        index = series.idxmax()\n",
    "    else:\n",
    "        index = series.idxmin()\n",
    "    return index, series[index]\n",
    "\n",
    "def on_key(event, channel, condition, erp_frame): # event.key, event.x, event.y, event.xdata, event.ydata\n",
    "    key_comp_order = {'1': 'p1', '2': 'n170', '3': 'p3'}\n",
    "    if event.key in ['1', '2', '3']:\n",
    "        closest_index = (erp_frame.index.to_series() - event.xdata).abs().idxmin()\n",
    "        row_number = erp_frame.index.get_loc(closest_index)\n",
    "        override_tuple =  max_index_and_value(erp_frame.iloc[range(row_number - 25, row_number + 25)], event.key in ['1', '3'])\n",
    "        # erp_info[f'{condition}_{channel}_{key_comp_order[event.key]}'] = override_tuple\n",
    "        erp_info[channel][condition][key_comp_order[event.key]] = override_tuple\n",
    "        display(erp_info[channel][condition])\n",
    "\n",
    "def is_figure_open(fig):\n",
    "    try:\n",
    "        while fig.number in plt.get_fignums():\n",
    "            plt.pause(0.1)\n",
    "    except:\n",
    "        plt.close(fig.number)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd5b56-7ec4-4142-adbf-272291a68be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "erp_info = {}\n",
    "\n",
    "evokeds = {}\n",
    "erp_frames = {}\n",
    "for chan in channel_interest:\n",
    "    erp_info[chan] = {}\n",
    "    for cond in condition_interest:\n",
    "        erp_info[chan][cond] = {}\n",
    "        evokeds[cond] = epochs[cond].average()\n",
    "        erp_frames[f'{cond}_{chan}'] = evokeds[cond].to_data_frame().set_index('time')[chan]\n",
    "        erp_info[chan][cond]['p1'] = max_index_and_value(erp_frames[f'{cond}_{chan}'].loc[p1_def[0]:p1_def[1]])\n",
    "        erp_info[chan][cond]['n170'] = max_index_and_value(erp_frames[f'{cond}_{chan}'].loc[n170_def[0]:n170_def[1]], find_max=False)\n",
    "        erp_info[chan][cond]['p3'] = max_index_and_value(erp_frames[f'{cond}_{chan}'].loc[p3_def[0]:p3_def[1]])\n",
    "erp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b9294-168c-4397-a9f7-7d4a9f251600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "for chan in channel_interest:\n",
    "    for cond in condition_interest:\n",
    "        on_key_partial = partial(on_key, channel=chan, condition=cond, erp_frame=erp_frames[f'{cond}_{chan}'])\n",
    "        comp_lines = [erp_info[chan][cond][comp][0] for comp in ['p1', 'n170', 'p3']]\n",
    "        comp_lines.insert(0, 0) # Make sure zero is still graphed\n",
    "        fig = mne.viz.plot_compare_evokeds(evokeds[cond], picks=chan, vlines=comp_lines)    \n",
    "        cid = fig[0].canvas.mpl_connect('key_press_event', on_key_partial)        \n",
    "        display(erp_info[chan][cond])\n",
    "        is_figure_open(fig[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea1668-6ea5-44e6-907c-ce9eb68e5b43",
   "metadata": {},
   "source": [
    "#### Break point\n",
    "\n",
    "Confirm the values in the `erp_info` dictionary before running the final cell and writing the peaks to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be68d1-d84e-4522-959d-bdfb35593f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chan in erp_info.keys():\n",
    "    print('Channel: ', chan)\n",
    "    for cond in erp_info[chan].keys():\n",
    "        print('\\tCondition: ', cond)\n",
    "        for comp in erp_info[chan][cond].keys():\n",
    "            print(f'\\t\\t{comp}\\t{erp_info[chan][cond][comp][0]}\\t{erp_info[chan][cond][comp][1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a39ee-fa20-4911-a34c-dfbb7361f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6441d-72df-496b-a95b-fc9ad222e6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
